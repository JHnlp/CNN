{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import lasagne\n",
    "from lasagne.regularization import regularize_layer_params, l2, l1\n",
    "\n",
    "from lasagne.layers import LocalResponseNormalization2DLayer as LRNLayer\n",
    "from lasagne.layers import GlobalPoolLayer\n",
    "\n",
    "batch_size = 40\n",
    "Conv2DLayer = lasagne.layers.Conv2DLayer\n",
    "bias = 0\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    face=sklearn.datasets.fetch_olivetti_faces(shuffle=True)\n",
    "    train_set=(face.data[0:200,].reshape((200,1,64,64)),face.target[0:200,].astype(np.int32))\n",
    "    test_set =(face.data[200:400,].reshape((200,1,64,64)),face.target[200:400,].astype(np.int32))\n",
    "    rval = [train_set, test_set]\n",
    "    return rval\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    \n",
    "    network = lasagne.layers.InputLayer(shape=(batch_size, 1, 64, 64),\n",
    "                                        input_var=input_var)\n",
    "   \n",
    "    network = lasagne.layers.NINLayer(network, num_units=24,nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeNormal(gain='relu'), b=lasagne.init.Constant(0))\n",
    "    \n",
    "    network = Conv2DLayer(network, num_filters=32, filter_size=(5, 5),nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeNormal(gain='relu'), b=lasagne.init.Constant(bias))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=3, stride=2)\n",
    "\n",
    "    network = lasagne.layers.NINLayer(network, num_units=64,nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeNormal(gain='relu'), b=lasagne.init.Constant(0))\n",
    "    \n",
    "    network = Conv2DLayer(network, num_filters=64, filter_size=(3, 3),nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeNormal(gain='relu'), b=lasagne.init.Constant(bias))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=3, stride=2)\n",
    "\n",
    "    network = lasagne.layers.NINLayer(network, num_units=64,nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeNormal(gain='relu'), b=lasagne.init.Constant(0))\n",
    "    \n",
    "    network = Conv2DLayer(network, num_filters=64, filter_size=(3, 3),nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeNormal(gain='relu'), b=lasagne.init.Constant(bias))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=3, stride=2)\n",
    "\n",
    "    #network = GlobalPoolLayer(network)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        lasagne.layers.dropout(network, p=.5),\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=40,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(num_epochs=200):\n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    datasets = load_data()\n",
    "    X_train, y_train = datasets[0]\n",
    "    X_test, y_test = datasets[1]\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    learnrate=0.02\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "\n",
    "    network = build_cnn(input_var)\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    l1_penalty = regularize_layer_params(network, l1)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()+0.001*l1_penalty\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    \n",
    "    #updates = lasagne.updates.adadelta(loss, params)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "            loss, params, learning_rate=learnrate, momentum=0.9)\n",
    "\n",
    "    \n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    \n",
    "    best_acc = 0\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        if epoch % 30 == 29:\n",
    "            learnrate*=0.8\n",
    "            #updates = lasagne.updates.adadelta(loss, params,learning_rate=learnrate)\n",
    "            updates = lasagne.updates.nesterov_momentum(\n",
    "                loss, params, learning_rate=learnrate, momentum=0.9)\n",
    "            train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        test_err = 0\n",
    "        test_acc = 0\n",
    "        test_batches = 0\n",
    "        for batch in iterate_minibatches(X_test, y_test,batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            test_err += err\n",
    "            test_acc += acc\n",
    "            test_batches += 1\n",
    "        test_err = test_err / test_batches\n",
    "        test_acc = test_acc / test_batches\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  test loss:\\t\\t{:.6f}\".format(test_err))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            test_acc * 100))\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            np.savez('ORL_Lenet.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    return best_acc\n",
    "\n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 0.538s\n",
      "  training loss:\t\t4.801144\n",
      "  test loss:\t\t3.834670\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 2 of 500 took 0.536s\n",
      "  training loss:\t\t4.559716\n",
      "  test loss:\t\t3.913258\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 3 of 500 took 0.534s\n",
      "  training loss:\t\t4.535548\n",
      "  test loss:\t\t3.912030\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 4 of 500 took 0.539s\n",
      "  training loss:\t\t4.583580\n",
      "  test loss:\t\t3.859636\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 5 of 500 took 0.536s\n",
      "  training loss:\t\t4.447699\n",
      "  test loss:\t\t3.827559\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 6 of 500 took 0.536s\n",
      "  training loss:\t\t4.479729\n",
      "  test loss:\t\t3.816812\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 7 of 500 took 0.535s\n",
      "  training loss:\t\t4.415109\n",
      "  test loss:\t\t3.809550\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 8 of 500 took 0.539s\n",
      "  training loss:\t\t4.383013\n",
      "  test loss:\t\t3.808697\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 9 of 500 took 0.536s\n",
      "  training loss:\t\t4.335175\n",
      "  test loss:\t\t3.811236\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 10 of 500 took 0.535s\n",
      "  training loss:\t\t4.357564\n",
      "  test loss:\t\t3.813514\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 11 of 500 took 0.535s\n",
      "  training loss:\t\t4.316397\n",
      "  test loss:\t\t3.813211\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 12 of 500 took 0.538s\n",
      "  training loss:\t\t4.321526\n",
      "  test loss:\t\t3.810336\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 13 of 500 took 0.536s\n",
      "  training loss:\t\t4.299820\n",
      "  test loss:\t\t3.807443\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 14 of 500 took 0.535s\n",
      "  training loss:\t\t4.254806\n",
      "  test loss:\t\t3.808771\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 15 of 500 took 0.537s\n",
      "  training loss:\t\t4.241637\n",
      "  test loss:\t\t3.809291\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 16 of 500 took 0.535s\n",
      "  training loss:\t\t4.265150\n",
      "  test loss:\t\t3.807414\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 17 of 500 took 0.537s\n",
      "  training loss:\t\t4.222143\n",
      "  test loss:\t\t3.808543\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 18 of 500 took 0.538s\n",
      "  training loss:\t\t4.242169\n",
      "  test loss:\t\t3.805046\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 19 of 500 took 0.538s\n",
      "  training loss:\t\t4.253086\n",
      "  test loss:\t\t3.800869\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 20 of 500 took 0.540s\n",
      "  training loss:\t\t4.221368\n",
      "  test loss:\t\t3.798975\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 21 of 500 took 0.539s\n",
      "  training loss:\t\t4.199890\n",
      "  test loss:\t\t3.799238\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 22 of 500 took 0.537s\n",
      "  training loss:\t\t4.175181\n",
      "  test loss:\t\t3.802081\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 23 of 500 took 0.537s\n",
      "  training loss:\t\t4.163427\n",
      "  test loss:\t\t3.808855\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 24 of 500 took 0.538s\n",
      "  training loss:\t\t4.156680\n",
      "  test loss:\t\t3.814042\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 25 of 500 took 0.535s\n",
      "  training loss:\t\t4.142525\n",
      "  test loss:\t\t3.814993\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 26 of 500 took 0.536s\n",
      "  training loss:\t\t4.179723\n",
      "  test loss:\t\t3.811480\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 27 of 500 took 0.535s\n",
      "  training loss:\t\t4.130320\n",
      "  test loss:\t\t3.808623\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 28 of 500 took 0.535s\n",
      "  training loss:\t\t4.146998\n",
      "  test loss:\t\t3.804689\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 29 of 500 took 0.535s\n",
      "  training loss:\t\t4.115316\n",
      "  test loss:\t\t3.800972\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 30 of 500 took 2.618s\n",
      "  training loss:\t\t4.098248\n",
      "  test loss:\t\t3.802337\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 31 of 500 took 0.540s\n",
      "  training loss:\t\t4.128164\n",
      "  test loss:\t\t3.802463\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 32 of 500 took 0.537s\n",
      "  training loss:\t\t4.100663\n",
      "  test loss:\t\t3.803118\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 33 of 500 took 0.534s\n",
      "  training loss:\t\t4.098560\n",
      "  test loss:\t\t3.802601\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 34 of 500 took 0.541s\n",
      "  training loss:\t\t4.079221\n",
      "  test loss:\t\t3.801956\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 35 of 500 took 0.535s\n",
      "  training loss:\t\t4.070937\n",
      "  test loss:\t\t3.803598\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 36 of 500 took 0.534s\n",
      "  training loss:\t\t4.077683\n",
      "  test loss:\t\t3.806178\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 37 of 500 took 0.535s\n",
      "  training loss:\t\t4.087438\n",
      "  test loss:\t\t3.807039\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 38 of 500 took 0.539s\n",
      "  training loss:\t\t4.070219\n",
      "  test loss:\t\t3.807253\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 39 of 500 took 0.534s\n",
      "  training loss:\t\t4.063416\n",
      "  test loss:\t\t3.806656\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 40 of 500 took 0.535s\n",
      "  training loss:\t\t4.063996\n",
      "  test loss:\t\t3.805191\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 41 of 500 took 0.536s\n",
      "  training loss:\t\t4.021741\n",
      "  test loss:\t\t3.806639\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 42 of 500 took 0.565s\n",
      "  training loss:\t\t4.025574\n",
      "  test loss:\t\t3.811167\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 43 of 500 took 0.540s\n",
      "  training loss:\t\t4.032595\n",
      "  test loss:\t\t3.814185\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 44 of 500 took 0.538s\n",
      "  training loss:\t\t4.040695\n",
      "  test loss:\t\t3.815142\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 45 of 500 took 0.544s\n",
      "  training loss:\t\t4.007975\n",
      "  test loss:\t\t3.815536\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 46 of 500 took 0.543s\n",
      "  training loss:\t\t4.031157\n",
      "  test loss:\t\t3.813377\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 47 of 500 took 0.541s\n",
      "  training loss:\t\t3.996155\n",
      "  test loss:\t\t3.813221\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 48 of 500 took 0.536s\n",
      "  training loss:\t\t4.004550\n",
      "  test loss:\t\t3.812320\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 49 of 500 took 0.538s\n",
      "  training loss:\t\t3.987153\n",
      "  test loss:\t\t3.812835\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 50 of 500 took 0.539s\n",
      "  training loss:\t\t3.987326\n",
      "  test loss:\t\t3.814398\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 51 of 500 took 0.536s\n",
      "  training loss:\t\t3.981547\n",
      "  test loss:\t\t3.815036\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 52 of 500 took 0.535s\n",
      "  training loss:\t\t3.972129\n",
      "  test loss:\t\t3.815676\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 53 of 500 took 0.534s\n",
      "  training loss:\t\t3.981893\n",
      "  test loss:\t\t3.814420\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 54 of 500 took 0.536s\n",
      "  training loss:\t\t3.961216\n",
      "  test loss:\t\t3.813598\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 55 of 500 took 0.536s\n",
      "  training loss:\t\t3.959387\n",
      "  test loss:\t\t3.813239\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 56 of 500 took 0.535s\n",
      "  training loss:\t\t3.954832\n",
      "  test loss:\t\t3.814550\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 57 of 500 took 0.536s\n",
      "  training loss:\t\t3.964192\n",
      "  test loss:\t\t3.814745\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 58 of 500 took 0.536s\n",
      "  training loss:\t\t3.946310\n",
      "  test loss:\t\t3.815772\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 59 of 500 took 0.543s\n",
      "  training loss:\t\t3.948336\n",
      "  test loss:\t\t3.815130\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 60 of 500 took 2.723s\n",
      "  training loss:\t\t3.938618\n",
      "  test loss:\t\t3.815011\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 61 of 500 took 0.535s\n",
      "  training loss:\t\t3.921091\n",
      "  test loss:\t\t3.815549\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 62 of 500 took 0.537s\n",
      "  training loss:\t\t3.927503\n",
      "  test loss:\t\t3.816093\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 63 of 500 took 0.541s\n",
      "  training loss:\t\t3.936649\n",
      "  test loss:\t\t3.815736\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 64 of 500 took 0.542s\n",
      "  training loss:\t\t3.928518\n",
      "  test loss:\t\t3.814623\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 65 of 500 took 0.535s\n",
      "  training loss:\t\t3.917053\n",
      "  test loss:\t\t3.814622\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 66 of 500 took 0.536s\n",
      "  training loss:\t\t3.903591\n",
      "  test loss:\t\t3.816029\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 67 of 500 took 0.542s\n",
      "  training loss:\t\t3.907235\n",
      "  test loss:\t\t3.817789\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 68 of 500 took 0.543s\n",
      "  training loss:\t\t3.928136\n",
      "  test loss:\t\t3.817371\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 69 of 500 took 0.536s\n",
      "  training loss:\t\t3.903417\n",
      "  test loss:\t\t3.816155\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 70 of 500 took 0.535s\n",
      "  training loss:\t\t3.903277\n",
      "  test loss:\t\t3.815821\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 71 of 500 took 0.538s\n",
      "  training loss:\t\t3.898615\n",
      "  test loss:\t\t3.815553\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 72 of 500 took 0.534s\n",
      "  training loss:\t\t3.891289\n",
      "  test loss:\t\t3.816145\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 73 of 500 took 0.535s\n",
      "  training loss:\t\t3.891171\n",
      "  test loss:\t\t3.815825\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 74 of 500 took 0.538s\n",
      "  training loss:\t\t3.886694\n",
      "  test loss:\t\t3.816099\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 75 of 500 took 0.535s\n",
      "  training loss:\t\t3.883326\n",
      "  test loss:\t\t3.815566\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 76 of 500 took 0.534s\n",
      "  training loss:\t\t3.870441\n",
      "  test loss:\t\t3.815063\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 77 of 500 took 0.543s\n",
      "  training loss:\t\t3.872393\n",
      "  test loss:\t\t3.815475\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 78 of 500 took 0.544s\n",
      "  training loss:\t\t3.872955\n",
      "  test loss:\t\t3.816319\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 79 of 500 took 0.536s\n",
      "  training loss:\t\t3.880096\n",
      "  test loss:\t\t3.815960\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 80 of 500 took 0.538s\n",
      "  training loss:\t\t3.864355\n",
      "  test loss:\t\t3.815353\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 81 of 500 took 0.542s\n",
      "  training loss:\t\t3.866426\n",
      "  test loss:\t\t3.814177\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 82 of 500 took 0.537s\n",
      "  training loss:\t\t3.861581\n",
      "  test loss:\t\t3.814420\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 83 of 500 took 0.538s\n",
      "  training loss:\t\t3.853483\n",
      "  test loss:\t\t3.814780\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 84 of 500 took 0.539s\n",
      "  training loss:\t\t3.845152\n",
      "  test loss:\t\t3.815986\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 85 of 500 took 0.541s\n",
      "  training loss:\t\t3.840091\n",
      "  test loss:\t\t3.817672\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 86 of 500 took 0.539s\n",
      "  training loss:\t\t3.844672\n",
      "  test loss:\t\t3.818317\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 87 of 500 took 0.539s\n",
      "  training loss:\t\t3.838847\n",
      "  test loss:\t\t3.818672\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 88 of 500 took 0.541s\n",
      "  training loss:\t\t3.837970\n",
      "  test loss:\t\t3.819018\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 89 of 500 took 0.541s\n",
      "  training loss:\t\t3.839784\n",
      "  test loss:\t\t3.817973\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 90 of 500 took 2.715s\n",
      "  training loss:\t\t3.842117\n",
      "  test loss:\t\t3.818008\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 91 of 500 took 0.536s\n",
      "  training loss:\t\t3.821536\n",
      "  test loss:\t\t3.817779\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 92 of 500 took 0.541s\n",
      "  training loss:\t\t3.825522\n",
      "  test loss:\t\t3.818217\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 93 of 500 took 0.538s\n",
      "  training loss:\t\t3.822730\n",
      "  test loss:\t\t3.818888\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 94 of 500 took 0.545s\n",
      "  training loss:\t\t3.826346\n",
      "  test loss:\t\t3.819174\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 95 of 500 took 0.542s\n",
      "  training loss:\t\t3.827727\n",
      "  test loss:\t\t3.818708\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 96 of 500 took 0.540s\n",
      "  training loss:\t\t3.837236\n",
      "  test loss:\t\t3.816816\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 97 of 500 took 0.545s\n",
      "  training loss:\t\t3.813594\n",
      "  test loss:\t\t3.815344\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 98 of 500 took 0.542s\n",
      "  training loss:\t\t3.816196\n",
      "  test loss:\t\t3.814586\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 99 of 500 took 0.539s\n",
      "  training loss:\t\t3.806289\n",
      "  test loss:\t\t3.814391\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 100 of 500 took 0.544s\n",
      "  training loss:\t\t3.820505\n",
      "  test loss:\t\t3.813338\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 101 of 500 took 0.538s\n",
      "  training loss:\t\t3.818788\n",
      "  test loss:\t\t3.811972\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 102 of 500 took 0.540s\n",
      "  training loss:\t\t3.808070\n",
      "  test loss:\t\t3.811129\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 103 of 500 took 0.540s\n",
      "  training loss:\t\t3.795076\n",
      "  test loss:\t\t3.811410\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 104 of 500 took 0.541s\n",
      "  training loss:\t\t3.805850\n",
      "  test loss:\t\t3.811597\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 105 of 500 took 0.541s\n",
      "  training loss:\t\t3.803931\n",
      "  test loss:\t\t3.811410\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 106 of 500 took 0.542s\n",
      "  training loss:\t\t3.797445\n",
      "  test loss:\t\t3.811164\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 107 of 500 took 0.540s\n",
      "  training loss:\t\t3.791007\n",
      "  test loss:\t\t3.811206\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 108 of 500 took 0.535s\n",
      "  training loss:\t\t3.780214\n",
      "  test loss:\t\t3.811716\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 109 of 500 took 0.535s\n",
      "  training loss:\t\t3.784623\n",
      "  test loss:\t\t3.812627\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 110 of 500 took 0.539s\n",
      "  training loss:\t\t3.783085\n",
      "  test loss:\t\t3.813515\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 111 of 500 took 0.534s\n",
      "  training loss:\t\t3.783443\n",
      "  test loss:\t\t3.814041\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 112 of 500 took 0.535s\n",
      "  training loss:\t\t3.780681\n",
      "  test loss:\t\t3.814808\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 113 of 500 took 0.536s\n",
      "  training loss:\t\t3.781399\n",
      "  test loss:\t\t3.815180\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 114 of 500 took 0.538s\n",
      "  training loss:\t\t3.778800\n",
      "  test loss:\t\t3.815399\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 115 of 500 took 0.535s\n",
      "  training loss:\t\t3.772595\n",
      "  test loss:\t\t3.815821\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 116 of 500 took 0.535s\n",
      "  training loss:\t\t3.773586\n",
      "  test loss:\t\t3.816465\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 117 of 500 took 0.540s\n",
      "  training loss:\t\t3.767107\n",
      "  test loss:\t\t3.816752\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 118 of 500 took 0.534s\n",
      "  training loss:\t\t3.773925\n",
      "  test loss:\t\t3.816212\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 119 of 500 took 0.535s\n",
      "  training loss:\t\t3.772048\n",
      "  test loss:\t\t3.815745\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 120 of 500 took 2.914s\n",
      "  training loss:\t\t3.771260\n",
      "  test loss:\t\t3.815925\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 121 of 500 took 0.535s\n",
      "  training loss:\t\t3.758342\n",
      "  test loss:\t\t3.816672\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 122 of 500 took 0.536s\n",
      "  training loss:\t\t3.769240\n",
      "  test loss:\t\t3.817154\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 123 of 500 took 0.538s\n",
      "  training loss:\t\t3.770225\n",
      "  test loss:\t\t3.817152\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 124 of 500 took 0.538s\n",
      "  training loss:\t\t3.759539\n",
      "  test loss:\t\t3.816949\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 125 of 500 took 0.536s\n",
      "  training loss:\t\t3.771713\n",
      "  test loss:\t\t3.816097\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 126 of 500 took 0.535s\n",
      "  training loss:\t\t3.759967\n",
      "  test loss:\t\t3.815542\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 127 of 500 took 0.536s\n",
      "  training loss:\t\t3.758317\n",
      "  test loss:\t\t3.815207\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 128 of 500 took 0.535s\n",
      "  training loss:\t\t3.751309\n",
      "  test loss:\t\t3.815157\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 129 of 500 took 0.536s\n",
      "  training loss:\t\t3.753613\n",
      "  test loss:\t\t3.815202\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 130 of 500 took 0.539s\n",
      "  training loss:\t\t3.751444\n",
      "  test loss:\t\t3.815491\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 131 of 500 took 0.536s\n",
      "  training loss:\t\t3.753917\n",
      "  test loss:\t\t3.815646\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 132 of 500 took 0.535s\n",
      "  training loss:\t\t3.751175\n",
      "  test loss:\t\t3.816133\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 133 of 500 took 0.536s\n",
      "  training loss:\t\t3.745180\n",
      "  test loss:\t\t3.816905\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 134 of 500 took 0.539s\n",
      "  training loss:\t\t3.739349\n",
      "  test loss:\t\t3.817865\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 135 of 500 took 0.534s\n",
      "  training loss:\t\t3.745181\n",
      "  test loss:\t\t3.818255\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 136 of 500 took 0.536s\n",
      "  training loss:\t\t3.742607\n",
      "  test loss:\t\t3.818390\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 137 of 500 took 0.540s\n",
      "  training loss:\t\t3.750048\n",
      "  test loss:\t\t3.818422\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 138 of 500 took 0.537s\n",
      "  training loss:\t\t3.741170\n",
      "  test loss:\t\t3.818500\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 139 of 500 took 0.534s\n",
      "  training loss:\t\t3.739820\n",
      "  test loss:\t\t3.818445\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 140 of 500 took 0.535s\n",
      "  training loss:\t\t3.735871\n",
      "  test loss:\t\t3.818365\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 141 of 500 took 0.537s\n",
      "  training loss:\t\t3.734600\n",
      "  test loss:\t\t3.818839\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 142 of 500 took 0.535s\n",
      "  training loss:\t\t3.735296\n",
      "  test loss:\t\t3.818998\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 143 of 500 took 0.535s\n",
      "  training loss:\t\t3.737640\n",
      "  test loss:\t\t3.819070\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 144 of 500 took 0.535s\n",
      "  training loss:\t\t3.733899\n",
      "  test loss:\t\t3.819180\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 145 of 500 took 0.537s\n",
      "  training loss:\t\t3.726564\n",
      "  test loss:\t\t3.819644\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 146 of 500 took 0.535s\n",
      "  training loss:\t\t3.729366\n",
      "  test loss:\t\t3.820172\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 147 of 500 took 0.535s\n",
      "  training loss:\t\t3.725989\n",
      "  test loss:\t\t3.820637\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 148 of 500 took 0.535s\n",
      "  training loss:\t\t3.734933\n",
      "  test loss:\t\t3.820536\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 149 of 500 took 0.536s\n",
      "  training loss:\t\t3.730325\n",
      "  test loss:\t\t3.820253\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 150 of 500 took 2.697s\n",
      "  training loss:\t\t3.741416\n",
      "  test loss:\t\t3.820274\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 151 of 500 took 0.538s\n",
      "  training loss:\t\t3.720461\n",
      "  test loss:\t\t3.820179\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 152 of 500 took 0.537s\n",
      "  training loss:\t\t3.728281\n",
      "  test loss:\t\t3.820313\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 153 of 500 took 0.536s\n",
      "  training loss:\t\t3.728014\n",
      "  test loss:\t\t3.820231\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 154 of 500 took 0.534s\n",
      "  training loss:\t\t3.720127\n",
      "  test loss:\t\t3.820482\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 155 of 500 took 0.535s\n",
      "  training loss:\t\t3.720020\n",
      "  test loss:\t\t3.820669\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 156 of 500 took 0.539s\n",
      "  training loss:\t\t3.723814\n",
      "  test loss:\t\t3.820663\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 157 of 500 took 0.538s\n",
      "  training loss:\t\t3.719307\n",
      "  test loss:\t\t3.820437\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 158 of 500 took 0.539s\n",
      "  training loss:\t\t3.715444\n",
      "  test loss:\t\t3.820597\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 159 of 500 took 0.535s\n",
      "  training loss:\t\t3.714281\n",
      "  test loss:\t\t3.820576\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 160 of 500 took 0.539s\n",
      "  training loss:\t\t3.726391\n",
      "  test loss:\t\t3.820323\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 161 of 500 took 0.538s\n",
      "  training loss:\t\t3.723039\n",
      "  test loss:\t\t3.819977\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 162 of 500 took 0.542s\n",
      "  training loss:\t\t3.719087\n",
      "  test loss:\t\t3.819671\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 163 of 500 took 0.539s\n",
      "  training loss:\t\t3.712356\n",
      "  test loss:\t\t3.819748\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 164 of 500 took 0.536s\n",
      "  training loss:\t\t3.715774\n",
      "  test loss:\t\t3.819918\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 165 of 500 took 0.536s\n",
      "  training loss:\t\t3.718327\n",
      "  test loss:\t\t3.819721\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 166 of 500 took 0.536s\n",
      "  training loss:\t\t3.715880\n",
      "  test loss:\t\t3.819404\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 167 of 500 took 0.538s\n",
      "  training loss:\t\t3.708603\n",
      "  test loss:\t\t3.819196\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 168 of 500 took 0.538s\n",
      "  training loss:\t\t3.715479\n",
      "  test loss:\t\t3.818974\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 169 of 500 took 0.536s\n",
      "  training loss:\t\t3.711243\n",
      "  test loss:\t\t3.818690\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 170 of 500 took 0.535s\n",
      "  training loss:\t\t3.709372\n",
      "  test loss:\t\t3.818137\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 171 of 500 took 0.535s\n",
      "  training loss:\t\t3.714964\n",
      "  test loss:\t\t3.817713\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 172 of 500 took 0.535s\n",
      "  training loss:\t\t3.710044\n",
      "  test loss:\t\t3.817341\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 173 of 500 took 0.538s\n",
      "  training loss:\t\t3.703934\n",
      "  test loss:\t\t3.817542\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 174 of 500 took 0.537s\n",
      "  training loss:\t\t3.708861\n",
      "  test loss:\t\t3.817857\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 175 of 500 took 0.537s\n",
      "  training loss:\t\t3.707584\n",
      "  test loss:\t\t3.818181\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 176 of 500 took 0.536s\n",
      "  training loss:\t\t3.713625\n",
      "  test loss:\t\t3.818286\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 177 of 500 took 0.535s\n",
      "  training loss:\t\t3.701404\n",
      "  test loss:\t\t3.818307\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 178 of 500 took 0.534s\n",
      "  training loss:\t\t3.700037\n",
      "  test loss:\t\t3.818549\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 179 of 500 took 0.539s\n",
      "  training loss:\t\t3.699571\n",
      "  test loss:\t\t3.818825\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 180 of 500 took 2.727s\n",
      "  training loss:\t\t3.698390\n",
      "  test loss:\t\t3.819285\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 181 of 500 took 0.537s\n",
      "  training loss:\t\t3.706410\n",
      "  test loss:\t\t3.819297\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 182 of 500 took 0.539s\n",
      "  training loss:\t\t3.707419\n",
      "  test loss:\t\t3.819118\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 183 of 500 took 0.536s\n",
      "  training loss:\t\t3.704173\n",
      "  test loss:\t\t3.818865\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 184 of 500 took 0.537s\n",
      "  training loss:\t\t3.704729\n",
      "  test loss:\t\t3.818620\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 185 of 500 took 0.537s\n",
      "  training loss:\t\t3.702877\n",
      "  test loss:\t\t3.818300\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 186 of 500 took 0.536s\n",
      "  training loss:\t\t3.692850\n",
      "  test loss:\t\t3.818179\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 187 of 500 took 0.538s\n",
      "  training loss:\t\t3.695857\n",
      "  test loss:\t\t3.818233\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 188 of 500 took 0.537s\n",
      "  training loss:\t\t3.698567\n",
      "  test loss:\t\t3.818554\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 189 of 500 took 0.536s\n",
      "  training loss:\t\t3.698356\n",
      "  test loss:\t\t3.818682\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 190 of 500 took 0.535s\n",
      "  training loss:\t\t3.692963\n",
      "  test loss:\t\t3.818989\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 191 of 500 took 0.536s\n",
      "  training loss:\t\t3.692335\n",
      "  test loss:\t\t3.819231\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 192 of 500 took 0.535s\n",
      "  training loss:\t\t3.696522\n",
      "  test loss:\t\t3.819408\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 193 of 500 took 0.537s\n",
      "  training loss:\t\t3.687787\n",
      "  test loss:\t\t3.819666\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 194 of 500 took 0.537s\n",
      "  training loss:\t\t3.689649\n",
      "  test loss:\t\t3.819892\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 195 of 500 took 0.537s\n",
      "  training loss:\t\t3.697129\n",
      "  test loss:\t\t3.819878\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 196 of 500 took 0.534s\n",
      "  training loss:\t\t3.693236\n",
      "  test loss:\t\t3.819593\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 197 of 500 took 0.535s\n",
      "  training loss:\t\t3.695233\n",
      "  test loss:\t\t3.819473\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 198 of 500 took 0.536s\n",
      "  training loss:\t\t3.695567\n",
      "  test loss:\t\t3.819054\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 199 of 500 took 0.538s\n",
      "  training loss:\t\t3.693496\n",
      "  test loss:\t\t3.818852\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 200 of 500 took 0.535s\n",
      "  training loss:\t\t3.702642\n",
      "  test loss:\t\t3.818230\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 201 of 500 took 0.535s\n",
      "  training loss:\t\t3.694094\n",
      "  test loss:\t\t3.817711\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 202 of 500 took 0.535s\n",
      "  training loss:\t\t3.684993\n",
      "  test loss:\t\t3.817608\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 203 of 500 took 0.538s\n",
      "  training loss:\t\t3.686950\n",
      "  test loss:\t\t3.817732\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 204 of 500 took 0.535s\n",
      "  training loss:\t\t3.685047\n",
      "  test loss:\t\t3.817904\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 205 of 500 took 0.535s\n",
      "  training loss:\t\t3.690936\n",
      "  test loss:\t\t3.818179\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 206 of 500 took 0.537s\n",
      "  training loss:\t\t3.689610\n",
      "  test loss:\t\t3.818181\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 207 of 500 took 0.542s\n",
      "  training loss:\t\t3.688637\n",
      "  test loss:\t\t3.817993\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 208 of 500 took 0.540s\n",
      "  training loss:\t\t3.679167\n",
      "  test loss:\t\t3.818053\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 209 of 500 took 0.535s\n",
      "  training loss:\t\t3.689115\n",
      "  test loss:\t\t3.818167\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 210 of 500 took 2.732s\n",
      "  training loss:\t\t3.688491\n",
      "  test loss:\t\t3.818302\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 211 of 500 took 0.546s\n",
      "  training loss:\t\t3.684182\n",
      "  test loss:\t\t3.818429\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 212 of 500 took 0.539s\n",
      "  training loss:\t\t3.688984\n",
      "  test loss:\t\t3.818507\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 213 of 500 took 0.535s\n",
      "  training loss:\t\t3.680582\n",
      "  test loss:\t\t3.818828\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 214 of 500 took 0.537s\n",
      "  training loss:\t\t3.689528\n",
      "  test loss:\t\t3.818987\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 215 of 500 took 0.542s\n",
      "  training loss:\t\t3.683765\n",
      "  test loss:\t\t3.819127\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 216 of 500 took 0.542s\n",
      "  training loss:\t\t3.683724\n",
      "  test loss:\t\t3.819178\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 217 of 500 took 0.546s\n",
      "  training loss:\t\t3.679697\n",
      "  test loss:\t\t3.819180\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 218 of 500 took 0.552s\n",
      "  training loss:\t\t3.688196\n",
      "  test loss:\t\t3.819097\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 219 of 500 took 0.549s\n",
      "  training loss:\t\t3.687608\n",
      "  test loss:\t\t3.818934\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 220 of 500 took 0.546s\n",
      "  training loss:\t\t3.683766\n",
      "  test loss:\t\t3.818774\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 221 of 500 took 0.546s\n",
      "  training loss:\t\t3.681245\n",
      "  test loss:\t\t3.818790\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 222 of 500 took 0.542s\n",
      "  training loss:\t\t3.681859\n",
      "  test loss:\t\t3.818886\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 223 of 500 took 0.540s\n",
      "  training loss:\t\t3.684927\n",
      "  test loss:\t\t3.818986\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 224 of 500 took 0.538s\n",
      "  training loss:\t\t3.678775\n",
      "  test loss:\t\t3.819004\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 225 of 500 took 0.535s\n",
      "  training loss:\t\t3.680367\n",
      "  test loss:\t\t3.819143\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 226 of 500 took 0.539s\n",
      "  training loss:\t\t3.681159\n",
      "  test loss:\t\t3.819353\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 227 of 500 took 0.538s\n",
      "  training loss:\t\t3.680894\n",
      "  test loss:\t\t3.819454\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 228 of 500 took 0.534s\n",
      "  training loss:\t\t3.678077\n",
      "  test loss:\t\t3.819690\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 229 of 500 took 0.535s\n",
      "  training loss:\t\t3.682223\n",
      "  test loss:\t\t3.819859\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 230 of 500 took 0.535s\n",
      "  training loss:\t\t3.680270\n",
      "  test loss:\t\t3.819944\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 231 of 500 took 0.540s\n",
      "  training loss:\t\t3.677804\n",
      "  test loss:\t\t3.819986\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 232 of 500 took 0.539s\n",
      "  training loss:\t\t3.669335\n",
      "  test loss:\t\t3.820225\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 233 of 500 took 0.540s\n",
      "  training loss:\t\t3.676575\n",
      "  test loss:\t\t3.820449\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 234 of 500 took 0.541s\n",
      "  training loss:\t\t3.681071\n",
      "  test loss:\t\t3.820475\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 235 of 500 took 0.536s\n",
      "  training loss:\t\t3.682313\n",
      "  test loss:\t\t3.820282\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 236 of 500 took 0.545s\n",
      "  training loss:\t\t3.684308\n",
      "  test loss:\t\t3.819912\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 237 of 500 took 0.539s\n",
      "  training loss:\t\t3.673056\n",
      "  test loss:\t\t3.819922\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 238 of 500 took 0.538s\n",
      "  training loss:\t\t3.678142\n",
      "  test loss:\t\t3.820011\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 239 of 500 took 0.537s\n",
      "  training loss:\t\t3.675558\n",
      "  test loss:\t\t3.820009\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 240 of 500 took 2.756s\n",
      "  training loss:\t\t3.677773\n",
      "  test loss:\t\t3.820098\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 241 of 500 took 0.542s\n",
      "  training loss:\t\t3.671910\n",
      "  test loss:\t\t3.820358\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 242 of 500 took 0.537s\n",
      "  training loss:\t\t3.672697\n",
      "  test loss:\t\t3.820631\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 243 of 500 took 0.540s\n",
      "  training loss:\t\t3.675445\n",
      "  test loss:\t\t3.820893\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 244 of 500 took 0.555s\n",
      "  training loss:\t\t3.676617\n",
      "  test loss:\t\t3.821018\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 245 of 500 took 0.552s\n",
      "  training loss:\t\t3.672237\n",
      "  test loss:\t\t3.821232\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 246 of 500 took 0.577s\n",
      "  training loss:\t\t3.681790\n",
      "  test loss:\t\t3.821277\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 247 of 500 took 0.585s\n",
      "  training loss:\t\t3.668819\n",
      "  test loss:\t\t3.821404\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 248 of 500 took 0.542s\n",
      "  training loss:\t\t3.666349\n",
      "  test loss:\t\t3.821538\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 249 of 500 took 0.552s\n",
      "  training loss:\t\t3.676810\n",
      "  test loss:\t\t3.821612\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 250 of 500 took 0.547s\n",
      "  training loss:\t\t3.671628\n",
      "  test loss:\t\t3.821727\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 251 of 500 took 0.550s\n",
      "  training loss:\t\t3.665077\n",
      "  test loss:\t\t3.822037\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 252 of 500 took 0.550s\n",
      "  training loss:\t\t3.680212\n",
      "  test loss:\t\t3.822175\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 253 of 500 took 0.552s\n",
      "  training loss:\t\t3.675611\n",
      "  test loss:\t\t3.822309\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 254 of 500 took 0.534s\n",
      "  training loss:\t\t3.680212\n",
      "  test loss:\t\t3.822107\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 255 of 500 took 0.538s\n",
      "  training loss:\t\t3.675154\n",
      "  test loss:\t\t3.821824\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 256 of 500 took 0.537s\n",
      "  training loss:\t\t3.674085\n",
      "  test loss:\t\t3.821700\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 257 of 500 took 0.568s\n",
      "  training loss:\t\t3.670547\n",
      "  test loss:\t\t3.821645\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 258 of 500 took 0.542s\n",
      "  training loss:\t\t3.674796\n",
      "  test loss:\t\t3.821552\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 259 of 500 took 0.536s\n",
      "  training loss:\t\t3.668846\n",
      "  test loss:\t\t3.821636\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 260 of 500 took 0.536s\n",
      "  training loss:\t\t3.674181\n",
      "  test loss:\t\t3.821575\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 261 of 500 took 0.535s\n",
      "  training loss:\t\t3.668871\n",
      "  test loss:\t\t3.821493\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 262 of 500 took 0.539s\n",
      "  training loss:\t\t3.669702\n",
      "  test loss:\t\t3.821312\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 263 of 500 took 0.536s\n",
      "  training loss:\t\t3.668400\n",
      "  test loss:\t\t3.821152\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 264 of 500 took 0.533s\n",
      "  training loss:\t\t3.671040\n",
      "  test loss:\t\t3.821068\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 265 of 500 took 0.533s\n",
      "  training loss:\t\t3.669123\n",
      "  test loss:\t\t3.821133\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 266 of 500 took 0.563s\n",
      "  training loss:\t\t3.664279\n",
      "  test loss:\t\t3.821298\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 267 of 500 took 0.550s\n",
      "  training loss:\t\t3.670671\n",
      "  test loss:\t\t3.821396\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 268 of 500 took 0.546s\n",
      "  training loss:\t\t3.681292\n",
      "  test loss:\t\t3.821290\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 269 of 500 took 0.574s\n",
      "  training loss:\t\t3.673189\n",
      "  test loss:\t\t3.821048\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 270 of 500 took 2.758s\n",
      "  training loss:\t\t3.664652\n",
      "  test loss:\t\t3.821298\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 271 of 500 took 0.535s\n",
      "  training loss:\t\t3.673115\n",
      "  test loss:\t\t3.821333\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 272 of 500 took 0.551s\n",
      "  training loss:\t\t3.673090\n",
      "  test loss:\t\t3.821242\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 273 of 500 took 0.541s\n",
      "  training loss:\t\t3.670263\n",
      "  test loss:\t\t3.821088\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 274 of 500 took 0.547s\n",
      "  training loss:\t\t3.671650\n",
      "  test loss:\t\t3.820997\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 275 of 500 took 0.539s\n",
      "  training loss:\t\t3.670346\n",
      "  test loss:\t\t3.820817\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 276 of 500 took 0.549s\n",
      "  training loss:\t\t3.666674\n",
      "  test loss:\t\t3.820755\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 277 of 500 took 0.537s\n",
      "  training loss:\t\t3.677690\n",
      "  test loss:\t\t3.820607\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 278 of 500 took 0.553s\n",
      "  training loss:\t\t3.666225\n",
      "  test loss:\t\t3.820457\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 279 of 500 took 0.536s\n",
      "  training loss:\t\t3.670604\n",
      "  test loss:\t\t3.820391\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 280 of 500 took 0.550s\n",
      "  training loss:\t\t3.662670\n",
      "  test loss:\t\t3.820491\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 281 of 500 took 0.536s\n",
      "  training loss:\t\t3.672404\n",
      "  test loss:\t\t3.820569\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 282 of 500 took 0.536s\n",
      "  training loss:\t\t3.667170\n",
      "  test loss:\t\t3.820591\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 283 of 500 took 0.542s\n",
      "  training loss:\t\t3.667744\n",
      "  test loss:\t\t3.820550\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 284 of 500 took 0.542s\n",
      "  training loss:\t\t3.663243\n",
      "  test loss:\t\t3.820588\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 285 of 500 took 0.539s\n",
      "  training loss:\t\t3.668558\n",
      "  test loss:\t\t3.820618\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 286 of 500 took 0.542s\n",
      "  training loss:\t\t3.663236\n",
      "  test loss:\t\t3.820722\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 287 of 500 took 0.540s\n",
      "  training loss:\t\t3.661907\n",
      "  test loss:\t\t3.821016\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 288 of 500 took 0.539s\n",
      "  training loss:\t\t3.673698\n",
      "  test loss:\t\t3.821180\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 289 of 500 took 0.540s\n",
      "  training loss:\t\t3.664081\n",
      "  test loss:\t\t3.821299\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 290 of 500 took 0.540s\n",
      "  training loss:\t\t3.665211\n",
      "  test loss:\t\t3.821405\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 291 of 500 took 0.537s\n",
      "  training loss:\t\t3.668143\n",
      "  test loss:\t\t3.821420\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 292 of 500 took 0.533s\n",
      "  training loss:\t\t3.661871\n",
      "  test loss:\t\t3.821457\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 293 of 500 took 0.534s\n",
      "  training loss:\t\t3.666761\n",
      "  test loss:\t\t3.821465\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 294 of 500 took 0.536s\n",
      "  training loss:\t\t3.661032\n",
      "  test loss:\t\t3.821482\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 295 of 500 took 0.534s\n",
      "  training loss:\t\t3.661865\n",
      "  test loss:\t\t3.821543\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 296 of 500 took 0.535s\n",
      "  training loss:\t\t3.671211\n",
      "  test loss:\t\t3.821435\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 297 of 500 took 0.537s\n",
      "  training loss:\t\t3.665373\n",
      "  test loss:\t\t3.821290\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 298 of 500 took 0.536s\n",
      "  training loss:\t\t3.662097\n",
      "  test loss:\t\t3.821244\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 299 of 500 took 0.535s\n",
      "  training loss:\t\t3.672173\n",
      "  test loss:\t\t3.821098\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 300 of 500 took 2.707s\n",
      "  training loss:\t\t3.668038\n",
      "  test loss:\t\t3.821171\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 301 of 500 took 0.534s\n",
      "  training loss:\t\t3.664190\n",
      "  test loss:\t\t3.821150\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 302 of 500 took 0.542s\n",
      "  training loss:\t\t3.669085\n",
      "  test loss:\t\t3.821081\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 303 of 500 took 0.557s\n",
      "  training loss:\t\t3.669844\n",
      "  test loss:\t\t3.820861\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 304 of 500 took 0.541s\n",
      "  training loss:\t\t3.668409\n",
      "  test loss:\t\t3.820559\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 305 of 500 took 0.546s\n",
      "  training loss:\t\t3.661328\n",
      "  test loss:\t\t3.820338\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 306 of 500 took 0.540s\n",
      "  training loss:\t\t3.668257\n",
      "  test loss:\t\t3.820297\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 307 of 500 took 0.537s\n",
      "  training loss:\t\t3.665799\n",
      "  test loss:\t\t3.820171\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 308 of 500 took 0.535s\n",
      "  training loss:\t\t3.659131\n",
      "  test loss:\t\t3.820117\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 309 of 500 took 0.547s\n",
      "  training loss:\t\t3.657827\n",
      "  test loss:\t\t3.820186\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 310 of 500 took 0.554s\n",
      "  training loss:\t\t3.669360\n",
      "  test loss:\t\t3.820166\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 311 of 500 took 0.533s\n",
      "  training loss:\t\t3.664079\n",
      "  test loss:\t\t3.820182\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 312 of 500 took 0.542s\n",
      "  training loss:\t\t3.665031\n",
      "  test loss:\t\t3.820256\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 313 of 500 took 0.539s\n",
      "  training loss:\t\t3.667159\n",
      "  test loss:\t\t3.820277\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 314 of 500 took 0.544s\n",
      "  training loss:\t\t3.666349\n",
      "  test loss:\t\t3.820298\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 315 of 500 took 0.535s\n",
      "  training loss:\t\t3.666670\n",
      "  test loss:\t\t3.820259\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 316 of 500 took 0.534s\n",
      "  training loss:\t\t3.658756\n",
      "  test loss:\t\t3.820255\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 317 of 500 took 0.535s\n",
      "  training loss:\t\t3.667354\n",
      "  test loss:\t\t3.820313\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 318 of 500 took 0.535s\n",
      "  training loss:\t\t3.663232\n",
      "  test loss:\t\t3.820263\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 319 of 500 took 0.539s\n",
      "  training loss:\t\t3.662157\n",
      "  test loss:\t\t3.820281\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 320 of 500 took 0.535s\n",
      "  training loss:\t\t3.666264\n",
      "  test loss:\t\t3.820190\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 321 of 500 took 0.534s\n",
      "  training loss:\t\t3.663348\n",
      "  test loss:\t\t3.820137\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 322 of 500 took 0.534s\n",
      "  training loss:\t\t3.660441\n",
      "  test loss:\t\t3.820211\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 323 of 500 took 0.537s\n",
      "  training loss:\t\t3.672255\n",
      "  test loss:\t\t3.820189\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 324 of 500 took 0.536s\n",
      "  training loss:\t\t3.661462\n",
      "  test loss:\t\t3.820160\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 325 of 500 took 0.535s\n",
      "  training loss:\t\t3.654169\n",
      "  test loss:\t\t3.820265\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 326 of 500 took 0.542s\n",
      "  training loss:\t\t3.659986\n",
      "  test loss:\t\t3.820488\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 327 of 500 took 0.536s\n",
      "  training loss:\t\t3.662852\n",
      "  test loss:\t\t3.820587\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 328 of 500 took 0.540s\n",
      "  training loss:\t\t3.658369\n",
      "  test loss:\t\t3.820613\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 329 of 500 took 0.536s\n",
      "  training loss:\t\t3.665440\n",
      "  test loss:\t\t3.820670\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 330 of 500 took 2.725s\n",
      "  training loss:\t\t3.667486\n",
      "  test loss:\t\t3.820729\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 331 of 500 took 0.540s\n",
      "  training loss:\t\t3.655568\n",
      "  test loss:\t\t3.820770\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 332 of 500 took 0.539s\n",
      "  training loss:\t\t3.660309\n",
      "  test loss:\t\t3.820710\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 333 of 500 took 0.540s\n",
      "  training loss:\t\t3.658631\n",
      "  test loss:\t\t3.820785\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 334 of 500 took 0.535s\n",
      "  training loss:\t\t3.658581\n",
      "  test loss:\t\t3.820888\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 335 of 500 took 0.537s\n",
      "  training loss:\t\t3.660191\n",
      "  test loss:\t\t3.820982\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 336 of 500 took 0.539s\n",
      "  training loss:\t\t3.661091\n",
      "  test loss:\t\t3.821093\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 337 of 500 took 0.543s\n",
      "  training loss:\t\t3.667166\n",
      "  test loss:\t\t3.821128\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 338 of 500 took 0.543s\n",
      "  training loss:\t\t3.663770\n",
      "  test loss:\t\t3.821046\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 339 of 500 took 0.561s\n",
      "  training loss:\t\t3.661394\n",
      "  test loss:\t\t3.820914\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 340 of 500 took 0.539s\n",
      "  training loss:\t\t3.657064\n",
      "  test loss:\t\t3.820926\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 341 of 500 took 0.536s\n",
      "  training loss:\t\t3.657458\n",
      "  test loss:\t\t3.821024\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 342 of 500 took 0.542s\n",
      "  training loss:\t\t3.659782\n",
      "  test loss:\t\t3.821074\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 343 of 500 took 0.546s\n",
      "  training loss:\t\t3.657801\n",
      "  test loss:\t\t3.821154\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 344 of 500 took 0.535s\n",
      "  training loss:\t\t3.665196\n",
      "  test loss:\t\t3.821193\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 345 of 500 took 0.535s\n",
      "  training loss:\t\t3.662789\n",
      "  test loss:\t\t3.821191\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 346 of 500 took 0.538s\n",
      "  training loss:\t\t3.663309\n",
      "  test loss:\t\t3.821171\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 347 of 500 took 0.538s\n",
      "  training loss:\t\t3.666744\n",
      "  test loss:\t\t3.821023\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 348 of 500 took 0.553s\n",
      "  training loss:\t\t3.665420\n",
      "  test loss:\t\t3.820882\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 349 of 500 took 0.550s\n",
      "  training loss:\t\t3.661895\n",
      "  test loss:\t\t3.820765\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 350 of 500 took 0.572s\n",
      "  training loss:\t\t3.657082\n",
      "  test loss:\t\t3.820679\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 351 of 500 took 0.575s\n",
      "  training loss:\t\t3.659924\n",
      "  test loss:\t\t3.820614\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 352 of 500 took 0.570s\n",
      "  training loss:\t\t3.663583\n",
      "  test loss:\t\t3.820560\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 353 of 500 took 0.562s\n",
      "  training loss:\t\t3.656701\n",
      "  test loss:\t\t3.820527\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 354 of 500 took 0.558s\n",
      "  training loss:\t\t3.667586\n",
      "  test loss:\t\t3.820413\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 355 of 500 took 0.543s\n",
      "  training loss:\t\t3.659534\n",
      "  test loss:\t\t3.820272\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 356 of 500 took 0.546s\n",
      "  training loss:\t\t3.659188\n",
      "  test loss:\t\t3.820216\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 357 of 500 took 0.604s\n",
      "  training loss:\t\t3.662706\n",
      "  test loss:\t\t3.820148\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 358 of 500 took 0.568s\n",
      "  training loss:\t\t3.661950\n",
      "  test loss:\t\t3.820055\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 359 of 500 took 0.535s\n",
      "  training loss:\t\t3.660069\n",
      "  test loss:\t\t3.820072\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 360 of 500 took 2.986s\n",
      "  training loss:\t\t3.663244\n",
      "  test loss:\t\t3.820099\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 361 of 500 took 0.537s\n",
      "  training loss:\t\t3.657801\n",
      "  test loss:\t\t3.820135\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 362 of 500 took 0.537s\n",
      "  training loss:\t\t3.653696\n",
      "  test loss:\t\t3.820203\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 363 of 500 took 0.537s\n",
      "  training loss:\t\t3.658357\n",
      "  test loss:\t\t3.820284\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 364 of 500 took 0.538s\n",
      "  training loss:\t\t3.660494\n",
      "  test loss:\t\t3.820229\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 365 of 500 took 0.603s\n",
      "  training loss:\t\t3.669427\n",
      "  test loss:\t\t3.820099\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 366 of 500 took 0.608s\n",
      "  training loss:\t\t3.661596\n",
      "  test loss:\t\t3.820002\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 367 of 500 took 0.578s\n",
      "  training loss:\t\t3.661227\n",
      "  test loss:\t\t3.819991\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 368 of 500 took 0.595s\n",
      "  training loss:\t\t3.666821\n",
      "  test loss:\t\t3.819922\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 369 of 500 took 0.560s\n",
      "  training loss:\t\t3.655204\n",
      "  test loss:\t\t3.819875\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 370 of 500 took 0.539s\n",
      "  training loss:\t\t3.661774\n",
      "  test loss:\t\t3.819893\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 371 of 500 took 0.539s\n",
      "  training loss:\t\t3.663223\n",
      "  test loss:\t\t3.819833\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 372 of 500 took 0.538s\n",
      "  training loss:\t\t3.654964\n",
      "  test loss:\t\t3.819777\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 373 of 500 took 0.565s\n",
      "  training loss:\t\t3.658192\n",
      "  test loss:\t\t3.819800\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 374 of 500 took 0.547s\n",
      "  training loss:\t\t3.658243\n",
      "  test loss:\t\t3.819840\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 375 of 500 took 0.540s\n",
      "  training loss:\t\t3.663285\n",
      "  test loss:\t\t3.819866\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 376 of 500 took 0.556s\n",
      "  training loss:\t\t3.654092\n",
      "  test loss:\t\t3.819843\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 377 of 500 took 0.540s\n",
      "  training loss:\t\t3.658708\n",
      "  test loss:\t\t3.819803\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 378 of 500 took 0.601s\n",
      "  training loss:\t\t3.657484\n",
      "  test loss:\t\t3.819727\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 379 of 500 took 0.555s\n",
      "  training loss:\t\t3.653776\n",
      "  test loss:\t\t3.819724\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 380 of 500 took 0.568s\n",
      "  training loss:\t\t3.660783\n",
      "  test loss:\t\t3.819746\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 381 of 500 took 0.542s\n",
      "  training loss:\t\t3.660933\n",
      "  test loss:\t\t3.819718\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 382 of 500 took 0.614s\n",
      "  training loss:\t\t3.666497\n",
      "  test loss:\t\t3.819650\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 383 of 500 took 0.618s\n",
      "  training loss:\t\t3.659547\n",
      "  test loss:\t\t3.819603\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 384 of 500 took 0.625s\n",
      "  training loss:\t\t3.660360\n",
      "  test loss:\t\t3.819612\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 385 of 500 took 0.620s\n",
      "  training loss:\t\t3.664025\n",
      "  test loss:\t\t3.819559\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 386 of 500 took 0.570s\n",
      "  training loss:\t\t3.663017\n",
      "  test loss:\t\t3.819470\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 387 of 500 took 0.572s\n",
      "  training loss:\t\t3.654949\n",
      "  test loss:\t\t3.819372\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 388 of 500 took 0.535s\n",
      "  training loss:\t\t3.654938\n",
      "  test loss:\t\t3.819318\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 389 of 500 took 0.540s\n",
      "  training loss:\t\t3.669166\n",
      "  test loss:\t\t3.819218\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 390 of 500 took 2.724s\n",
      "  training loss:\t\t3.657646\n",
      "  test loss:\t\t3.819298\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 391 of 500 took 0.535s\n",
      "  training loss:\t\t3.656522\n",
      "  test loss:\t\t3.819339\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 392 of 500 took 0.544s\n",
      "  training loss:\t\t3.660646\n",
      "  test loss:\t\t3.819366\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 393 of 500 took 0.543s\n",
      "  training loss:\t\t3.660290\n",
      "  test loss:\t\t3.819349\n",
      "  validation accuracy:\t\t1.50 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7c9e589ebb04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-3c54a9a7fc94>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(num_epochs)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mtest_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mtest_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

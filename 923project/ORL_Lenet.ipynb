{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 750 Ti (CNMeM is disabled, CuDNN 3007)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import lasagne\n",
    "from lasagne.regularization import regularize_layer_params, l2, l1\n",
    "\n",
    "from lasagne.layers import LocalResponseNormalization2DLayer as LRNLayer\n",
    "from lasagne.layers import GlobalPoolLayer\n",
    "\n",
    "batch_size = 40\n",
    "Conv2DLayer = lasagne.layers.Conv2DLayer\n",
    "bias = 0\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    face=sklearn.datasets.fetch_olivetti_faces(shuffle=True)\n",
    "    train_set=(face.data[0:200,].reshape((200,1,64,64)),face.target[0:200,].astype(np.int32))\n",
    "    test_set =(face.data[200:400,].reshape((200,1,64,64)),face.target[200:400,].astype(np.int32))\n",
    "    rval = [train_set, test_set]\n",
    "    return rval\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    \n",
    "    network = lasagne.layers.InputLayer(shape=(batch_size, 1, 64, 64),\n",
    "                                        input_var=input_var)\n",
    "   \n",
    "    network = lasagne.layers.NINLayer(network, num_units=24,nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeUniform(gain=1.0, c01b=False), b=lasagne.init.Constant(0))\n",
    "    \n",
    "    network = Conv2DLayer(network, num_filters=32, filter_size=(5, 5),nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeUniform(gain=1.0, c01b=False), b=lasagne.init.Constant(bias))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=3, stride=2)\n",
    "\n",
    "    network = lasagne.layers.NINLayer(network, num_units=64,nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeUniform(gain=1.0, c01b=False), b=lasagne.init.Constant(0))\n",
    "    \n",
    "    network = Conv2DLayer(network, num_filters=64, filter_size=(3, 3),nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeUniform(gain=1.0, c01b=False), b=lasagne.init.Constant(bias))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=3, stride=2)\n",
    "\n",
    "    network = lasagne.layers.NINLayer(network, num_units=64,nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeUniform(gain=1.0, c01b=False), b=lasagne.init.Constant(0))\n",
    "    \n",
    "    network = Conv2DLayer(network, num_filters=64, filter_size=(3, 3),nonlinearity = lasagne.nonlinearities.sigmoid, W=lasagne.init.HeUniform(gain=1.0, c01b=False), b=lasagne.init.Constant(bias))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=3, stride=2)\n",
    "\n",
    "    #network = GlobalPoolLayer(network)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        lasagne.layers.dropout(network, p=.5),\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=40,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(num_epochs=200):\n",
    "    # Load the dataset\n",
    "    print(\"Loading data...\")\n",
    "    datasets = load_data()\n",
    "    X_train, y_train = datasets[0]\n",
    "    X_test, y_test = datasets[1]\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.ivector('targets')\n",
    "    learnrate=0.02\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "\n",
    "    network = build_cnn(input_var)\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    l1_penalty = regularize_layer_params(network, l1)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()+0.001*l1_penalty\n",
    "    # We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "    # Create update expressions for training, i.e., how to modify the\n",
    "    # parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    \n",
    "    #updates = lasagne.updates.adadelta(loss, params)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "            loss, params, learning_rate=learnrate, momentum=0.9)\n",
    "\n",
    "    \n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    \n",
    "    best_acc = 0\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        if epoch % 30 == 29:\n",
    "            learnrate*=0.8\n",
    "            #updates = lasagne.updates.adadelta(loss, params,learning_rate=learnrate)\n",
    "            updates = lasagne.updates.nesterov_momentum(\n",
    "                loss, params, learning_rate=learnrate, momentum=0.9)\n",
    "            train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        test_err = 0\n",
    "        test_acc = 0\n",
    "        test_batches = 0\n",
    "        for batch in iterate_minibatches(X_test, y_test,batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            test_err += err\n",
    "            test_acc += acc\n",
    "            test_batches += 1\n",
    "        test_err = test_err / test_batches\n",
    "        test_acc = test_acc / test_batches\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  test loss:\\t\\t{:.6f}\".format(test_err))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            test_acc * 100))\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            np.savez('ORL_Lenet.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    return best_acc\n",
    "\n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 0.555s\n",
      "  training loss:\t\t4.862448\n",
      "  test loss:\t\t3.779798\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 2 of 500 took 0.534s\n",
      "  training loss:\t\t4.625038\n",
      "  test loss:\t\t3.912777\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 3 of 500 took 0.559s\n",
      "  training loss:\t\t4.600325\n",
      "  test loss:\t\t3.956594\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 4 of 500 took 0.552s\n",
      "  training loss:\t\t4.569967\n",
      "  test loss:\t\t3.903042\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 5 of 500 took 0.595s\n",
      "  training loss:\t\t4.466462\n",
      "  test loss:\t\t3.859845\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 6 of 500 took 0.576s\n",
      "  training loss:\t\t4.454898\n",
      "  test loss:\t\t3.836588\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 7 of 500 took 0.536s\n",
      "  training loss:\t\t4.413596\n",
      "  test loss:\t\t3.827159\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 8 of 500 took 0.536s\n",
      "  training loss:\t\t4.408576\n",
      "  test loss:\t\t3.817594\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 9 of 500 took 0.580s\n",
      "  training loss:\t\t4.380758\n",
      "  test loss:\t\t3.808667\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 10 of 500 took 0.593s\n",
      "  training loss:\t\t4.294226\n",
      "  test loss:\t\t3.805316\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 11 of 500 took 0.572s\n",
      "  training loss:\t\t4.341602\n",
      "  test loss:\t\t3.799220\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 12 of 500 took 0.536s\n",
      "  training loss:\t\t4.285658\n",
      "  test loss:\t\t3.796202\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 13 of 500 took 0.537s\n",
      "  training loss:\t\t4.295384\n",
      "  test loss:\t\t3.797102\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 14 of 500 took 0.537s\n",
      "  training loss:\t\t4.282278\n",
      "  test loss:\t\t3.799779\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 15 of 500 took 0.537s\n",
      "  training loss:\t\t4.258892\n",
      "  test loss:\t\t3.799966\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 16 of 500 took 0.582s\n",
      "  training loss:\t\t4.217352\n",
      "  test loss:\t\t3.801423\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 17 of 500 took 0.535s\n",
      "  training loss:\t\t4.206021\n",
      "  test loss:\t\t3.805351\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 18 of 500 took 0.535s\n",
      "  training loss:\t\t4.218094\n",
      "  test loss:\t\t3.808817\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 19 of 500 took 0.556s\n",
      "  training loss:\t\t4.217051\n",
      "  test loss:\t\t3.808195\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 20 of 500 took 0.579s\n",
      "  training loss:\t\t4.190622\n",
      "  test loss:\t\t3.806312\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 21 of 500 took 0.565s\n",
      "  training loss:\t\t4.166528\n",
      "  test loss:\t\t3.808156\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 22 of 500 took 0.590s\n",
      "  training loss:\t\t4.182684\n",
      "  test loss:\t\t3.810276\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 23 of 500 took 0.569s\n",
      "  training loss:\t\t4.187779\n",
      "  test loss:\t\t3.807458\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 24 of 500 took 0.536s\n",
      "  training loss:\t\t4.192502\n",
      "  test loss:\t\t3.801775\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 25 of 500 took 0.536s\n",
      "  training loss:\t\t4.152422\n",
      "  test loss:\t\t3.798263\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 26 of 500 took 0.537s\n",
      "  training loss:\t\t4.136957\n",
      "  test loss:\t\t3.796637\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 27 of 500 took 0.574s\n",
      "  training loss:\t\t4.133162\n",
      "  test loss:\t\t3.796797\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 28 of 500 took 0.569s\n",
      "  training loss:\t\t4.128898\n",
      "  test loss:\t\t3.798302\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 29 of 500 took 0.536s\n",
      "  training loss:\t\t4.120799\n",
      "  test loss:\t\t3.799523\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 30 of 500 took 2.665s\n",
      "  training loss:\t\t4.111386\n",
      "  test loss:\t\t3.800813\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 31 of 500 took 0.536s\n",
      "  training loss:\t\t4.107749\n",
      "  test loss:\t\t3.799896\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 32 of 500 took 0.537s\n",
      "  training loss:\t\t4.101920\n",
      "  test loss:\t\t3.798265\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 33 of 500 took 0.541s\n",
      "  training loss:\t\t4.094168\n",
      "  test loss:\t\t3.797462\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 34 of 500 took 0.535s\n",
      "  training loss:\t\t4.085463\n",
      "  test loss:\t\t3.797133\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 35 of 500 took 0.535s\n",
      "  training loss:\t\t4.076970\n",
      "  test loss:\t\t3.796631\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 36 of 500 took 0.542s\n",
      "  training loss:\t\t4.068745\n",
      "  test loss:\t\t3.797280\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 37 of 500 took 0.558s\n",
      "  training loss:\t\t4.077175\n",
      "  test loss:\t\t3.797720\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 38 of 500 took 0.591s\n",
      "  training loss:\t\t4.066582\n",
      "  test loss:\t\t3.799265\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 39 of 500 took 0.609s\n",
      "  training loss:\t\t4.058523\n",
      "  test loss:\t\t3.800295\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 40 of 500 took 0.607s\n",
      "  training loss:\t\t4.060274\n",
      "  test loss:\t\t3.801206\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 41 of 500 took 0.593s\n",
      "  training loss:\t\t4.030657\n",
      "  test loss:\t\t3.802016\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 42 of 500 took 0.536s\n",
      "  training loss:\t\t4.034397\n",
      "  test loss:\t\t3.802083\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 43 of 500 took 0.585s\n",
      "  training loss:\t\t4.051042\n",
      "  test loss:\t\t3.799841\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 44 of 500 took 0.558s\n",
      "  training loss:\t\t4.023498\n",
      "  test loss:\t\t3.799271\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 45 of 500 took 0.554s\n",
      "  training loss:\t\t4.021867\n",
      "  test loss:\t\t3.798147\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 46 of 500 took 0.567s\n",
      "  training loss:\t\t3.993035\n",
      "  test loss:\t\t3.800045\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 47 of 500 took 0.584s\n",
      "  training loss:\t\t3.998622\n",
      "  test loss:\t\t3.802684\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 48 of 500 took 0.561s\n",
      "  training loss:\t\t3.995700\n",
      "  test loss:\t\t3.806837\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 49 of 500 took 0.540s\n",
      "  training loss:\t\t3.996693\n",
      "  test loss:\t\t3.807862\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 50 of 500 took 0.564s\n",
      "  training loss:\t\t3.987039\n",
      "  test loss:\t\t3.808578\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 51 of 500 took 0.536s\n",
      "  training loss:\t\t3.986569\n",
      "  test loss:\t\t3.808425\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 52 of 500 took 0.584s\n",
      "  training loss:\t\t3.983281\n",
      "  test loss:\t\t3.807935\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 53 of 500 took 0.572s\n",
      "  training loss:\t\t3.981475\n",
      "  test loss:\t\t3.807579\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 54 of 500 took 0.538s\n",
      "  training loss:\t\t3.962100\n",
      "  test loss:\t\t3.808907\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 55 of 500 took 0.537s\n",
      "  training loss:\t\t3.955219\n",
      "  test loss:\t\t3.810300\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 56 of 500 took 0.542s\n",
      "  training loss:\t\t3.953633\n",
      "  test loss:\t\t3.811053\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 57 of 500 took 0.569s\n",
      "  training loss:\t\t3.955320\n",
      "  test loss:\t\t3.810180\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 58 of 500 took 0.626s\n",
      "  training loss:\t\t3.943624\n",
      "  test loss:\t\t3.809535\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 59 of 500 took 0.537s\n",
      "  training loss:\t\t3.948316\n",
      "  test loss:\t\t3.807684\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 60 of 500 took 2.717s\n",
      "  training loss:\t\t3.926320\n",
      "  test loss:\t\t3.809428\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 61 of 500 took 0.535s\n",
      "  training loss:\t\t3.928975\n",
      "  test loss:\t\t3.811392\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 62 of 500 took 0.532s\n",
      "  training loss:\t\t3.945403\n",
      "  test loss:\t\t3.812166\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 63 of 500 took 0.609s\n",
      "  training loss:\t\t3.921240\n",
      "  test loss:\t\t3.813980\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 64 of 500 took 0.557s\n",
      "  training loss:\t\t3.928003\n",
      "  test loss:\t\t3.815509\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 65 of 500 took 0.536s\n",
      "  training loss:\t\t3.931942\n",
      "  test loss:\t\t3.814114\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 66 of 500 took 0.536s\n",
      "  training loss:\t\t3.926831\n",
      "  test loss:\t\t3.811043\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 67 of 500 took 0.536s\n",
      "  training loss:\t\t3.921243\n",
      "  test loss:\t\t3.808168\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 68 of 500 took 0.534s\n",
      "  training loss:\t\t3.899866\n",
      "  test loss:\t\t3.807724\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 69 of 500 took 0.534s\n",
      "  training loss:\t\t3.908230\n",
      "  test loss:\t\t3.807302\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 70 of 500 took 0.534s\n",
      "  training loss:\t\t3.898711\n",
      "  test loss:\t\t3.808385\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 71 of 500 took 0.533s\n",
      "  training loss:\t\t3.897110\n",
      "  test loss:\t\t3.809305\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 72 of 500 took 0.532s\n",
      "  training loss:\t\t3.901810\n",
      "  test loss:\t\t3.809301\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 73 of 500 took 0.533s\n",
      "  training loss:\t\t3.882078\n",
      "  test loss:\t\t3.810055\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 74 of 500 took 0.532s\n",
      "  training loss:\t\t3.887748\n",
      "  test loss:\t\t3.811369\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 75 of 500 took 0.533s\n",
      "  training loss:\t\t3.890015\n",
      "  test loss:\t\t3.810628\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 76 of 500 took 0.534s\n",
      "  training loss:\t\t3.874876\n",
      "  test loss:\t\t3.810224\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 77 of 500 took 0.533s\n",
      "  training loss:\t\t3.874224\n",
      "  test loss:\t\t3.810168\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 78 of 500 took 0.534s\n",
      "  training loss:\t\t3.862627\n",
      "  test loss:\t\t3.810750\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 79 of 500 took 0.532s\n",
      "  training loss:\t\t3.867987\n",
      "  test loss:\t\t3.811422\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 80 of 500 took 0.533s\n",
      "  training loss:\t\t3.856458\n",
      "  test loss:\t\t3.812161\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 81 of 500 took 0.533s\n",
      "  training loss:\t\t3.857899\n",
      "  test loss:\t\t3.812650\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 82 of 500 took 0.533s\n",
      "  training loss:\t\t3.859346\n",
      "  test loss:\t\t3.812671\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 83 of 500 took 0.534s\n",
      "  training loss:\t\t3.849064\n",
      "  test loss:\t\t3.812905\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 84 of 500 took 0.533s\n",
      "  training loss:\t\t3.844313\n",
      "  test loss:\t\t3.814104\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 85 of 500 took 0.533s\n",
      "  training loss:\t\t3.838793\n",
      "  test loss:\t\t3.815839\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 86 of 500 took 0.531s\n",
      "  training loss:\t\t3.836309\n",
      "  test loss:\t\t3.817327\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 87 of 500 took 0.535s\n",
      "  training loss:\t\t3.836863\n",
      "  test loss:\t\t3.819136\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 88 of 500 took 0.533s\n",
      "  training loss:\t\t3.840061\n",
      "  test loss:\t\t3.820442\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 89 of 500 took 0.533s\n",
      "  training loss:\t\t3.838537\n",
      "  test loss:\t\t3.820304\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 90 of 500 took 2.702s\n",
      "  training loss:\t\t3.826217\n",
      "  test loss:\t\t3.820582\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 91 of 500 took 0.537s\n",
      "  training loss:\t\t3.832884\n",
      "  test loss:\t\t3.819669\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 92 of 500 took 0.536s\n",
      "  training loss:\t\t3.825323\n",
      "  test loss:\t\t3.819528\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 93 of 500 took 0.534s\n",
      "  training loss:\t\t3.824380\n",
      "  test loss:\t\t3.819513\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 94 of 500 took 0.534s\n",
      "  training loss:\t\t3.812588\n",
      "  test loss:\t\t3.819669\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 95 of 500 took 0.535s\n",
      "  training loss:\t\t3.820826\n",
      "  test loss:\t\t3.819801\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 96 of 500 took 0.533s\n",
      "  training loss:\t\t3.822606\n",
      "  test loss:\t\t3.819211\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 97 of 500 took 0.537s\n",
      "  training loss:\t\t3.806582\n",
      "  test loss:\t\t3.818896\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 98 of 500 took 0.534s\n",
      "  training loss:\t\t3.807295\n",
      "  test loss:\t\t3.818901\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 99 of 500 took 0.534s\n",
      "  training loss:\t\t3.803756\n",
      "  test loss:\t\t3.819537\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 100 of 500 took 0.535s\n",
      "  training loss:\t\t3.805728\n",
      "  test loss:\t\t3.819716\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 101 of 500 took 0.534s\n",
      "  training loss:\t\t3.808348\n",
      "  test loss:\t\t3.819343\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 102 of 500 took 0.537s\n",
      "  training loss:\t\t3.798467\n",
      "  test loss:\t\t3.818635\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 103 of 500 took 0.534s\n",
      "  training loss:\t\t3.804067\n",
      "  test loss:\t\t3.818343\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 104 of 500 took 0.533s\n",
      "  training loss:\t\t3.797422\n",
      "  test loss:\t\t3.818364\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 105 of 500 took 0.536s\n",
      "  training loss:\t\t3.793142\n",
      "  test loss:\t\t3.818685\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 106 of 500 took 0.531s\n",
      "  training loss:\t\t3.794597\n",
      "  test loss:\t\t3.818469\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 107 of 500 took 0.537s\n",
      "  training loss:\t\t3.800754\n",
      "  test loss:\t\t3.817733\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 108 of 500 took 0.566s\n",
      "  training loss:\t\t3.791317\n",
      "  test loss:\t\t3.817151\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 109 of 500 took 0.585s\n",
      "  training loss:\t\t3.784953\n",
      "  test loss:\t\t3.817430\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 110 of 500 took 0.541s\n",
      "  training loss:\t\t3.789160\n",
      "  test loss:\t\t3.817594\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 111 of 500 took 0.574s\n",
      "  training loss:\t\t3.785651\n",
      "  test loss:\t\t3.816552\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 112 of 500 took 0.575s\n",
      "  training loss:\t\t3.781309\n",
      "  test loss:\t\t3.816211\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 113 of 500 took 0.565s\n",
      "  training loss:\t\t3.778847\n",
      "  test loss:\t\t3.816214\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 114 of 500 took 0.577s\n",
      "  training loss:\t\t3.778358\n",
      "  test loss:\t\t3.816362\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 115 of 500 took 0.577s\n",
      "  training loss:\t\t3.773885\n",
      "  test loss:\t\t3.816452\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 116 of 500 took 0.571s\n",
      "  training loss:\t\t3.771908\n",
      "  test loss:\t\t3.816422\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 117 of 500 took 0.572s\n",
      "  training loss:\t\t3.768719\n",
      "  test loss:\t\t3.816559\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 118 of 500 took 0.581s\n",
      "  training loss:\t\t3.759579\n",
      "  test loss:\t\t3.816752\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 119 of 500 took 0.544s\n",
      "  training loss:\t\t3.768411\n",
      "  test loss:\t\t3.816921\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 120 of 500 took 2.808s\n",
      "  training loss:\t\t3.763701\n",
      "  test loss:\t\t3.817724\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 121 of 500 took 0.537s\n",
      "  training loss:\t\t3.763782\n",
      "  test loss:\t\t3.818372\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 122 of 500 took 0.570s\n",
      "  training loss:\t\t3.760378\n",
      "  test loss:\t\t3.818569\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 123 of 500 took 0.562s\n",
      "  training loss:\t\t3.759845\n",
      "  test loss:\t\t3.819077\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 124 of 500 took 0.561s\n",
      "  training loss:\t\t3.757061\n",
      "  test loss:\t\t3.819558\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 125 of 500 took 0.542s\n",
      "  training loss:\t\t3.760460\n",
      "  test loss:\t\t3.819306\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 126 of 500 took 0.544s\n",
      "  training loss:\t\t3.762782\n",
      "  test loss:\t\t3.818609\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 127 of 500 took 0.577s\n",
      "  training loss:\t\t3.756573\n",
      "  test loss:\t\t3.817998\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 128 of 500 took 0.600s\n",
      "  training loss:\t\t3.764913\n",
      "  test loss:\t\t3.817294\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 129 of 500 took 0.561s\n",
      "  training loss:\t\t3.750101\n",
      "  test loss:\t\t3.817431\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 130 of 500 took 0.545s\n",
      "  training loss:\t\t3.755670\n",
      "  test loss:\t\t3.817275\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 131 of 500 took 0.562s\n",
      "  training loss:\t\t3.755217\n",
      "  test loss:\t\t3.816549\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 132 of 500 took 0.571s\n",
      "  training loss:\t\t3.748127\n",
      "  test loss:\t\t3.816076\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 133 of 500 took 0.547s\n",
      "  training loss:\t\t3.737362\n",
      "  test loss:\t\t3.816026\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 134 of 500 took 0.540s\n",
      "  training loss:\t\t3.748143\n",
      "  test loss:\t\t3.816036\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 135 of 500 took 0.618s\n",
      "  training loss:\t\t3.740101\n",
      "  test loss:\t\t3.816017\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 136 of 500 took 0.539s\n",
      "  training loss:\t\t3.736189\n",
      "  test loss:\t\t3.816181\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 137 of 500 took 0.541s\n",
      "  training loss:\t\t3.736694\n",
      "  test loss:\t\t3.816860\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 138 of 500 took 0.537s\n",
      "  training loss:\t\t3.741264\n",
      "  test loss:\t\t3.817324\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 139 of 500 took 0.536s\n",
      "  training loss:\t\t3.741489\n",
      "  test loss:\t\t3.817275\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 140 of 500 took 0.535s\n",
      "  training loss:\t\t3.748976\n",
      "  test loss:\t\t3.816670\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 141 of 500 took 0.534s\n",
      "  training loss:\t\t3.735238\n",
      "  test loss:\t\t3.816119\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 142 of 500 took 0.535s\n",
      "  training loss:\t\t3.734257\n",
      "  test loss:\t\t3.815864\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 143 of 500 took 0.537s\n",
      "  training loss:\t\t3.731179\n",
      "  test loss:\t\t3.816034\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 144 of 500 took 0.539s\n",
      "  training loss:\t\t3.741704\n",
      "  test loss:\t\t3.815912\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 145 of 500 took 0.536s\n",
      "  training loss:\t\t3.733261\n",
      "  test loss:\t\t3.815523\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 146 of 500 took 0.536s\n",
      "  training loss:\t\t3.729860\n",
      "  test loss:\t\t3.815219\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 147 of 500 took 0.544s\n",
      "  training loss:\t\t3.733095\n",
      "  test loss:\t\t3.815105\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 148 of 500 took 0.542s\n",
      "  training loss:\t\t3.727764\n",
      "  test loss:\t\t3.814864\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 149 of 500 took 0.567s\n",
      "  training loss:\t\t3.736505\n",
      "  test loss:\t\t3.814000\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 150 of 500 took 2.953s\n",
      "  training loss:\t\t3.722225\n",
      "  test loss:\t\t3.814610\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 151 of 500 took 0.547s\n",
      "  training loss:\t\t3.727122\n",
      "  test loss:\t\t3.815135\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 152 of 500 took 0.590s\n",
      "  training loss:\t\t3.721554\n",
      "  test loss:\t\t3.815504\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 153 of 500 took 0.545s\n",
      "  training loss:\t\t3.727852\n",
      "  test loss:\t\t3.815636\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 154 of 500 took 0.544s\n",
      "  training loss:\t\t3.723496\n",
      "  test loss:\t\t3.815969\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 155 of 500 took 0.542s\n",
      "  training loss:\t\t3.720811\n",
      "  test loss:\t\t3.816807\n",
      "  validation accuracy:\t\t1.50 %\n",
      "Epoch 156 of 500 took 0.538s\n",
      "  training loss:\t\t3.722744\n",
      "  test loss:\t\t3.817165\n",
      "  validation accuracy:\t\t1.50 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7c9e589ebb04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-3c54a9a7fc94>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(num_epochs)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
